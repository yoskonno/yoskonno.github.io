{"componentChunkName":"component---src-templates-tag-js","path":"/tags/nlp/","result":{"data":{"site":{"siteMetadata":{"title":"もばらぶエンジニアブログ"}},"allWordpressPost":{"totalCount":2,"edges":[{"node":{"id":"95750ad7-18e9-5b24-b50b-0a3d60fc50f2","title":"機械学習・自然言語処理のお勧め本など","excerpt":"<p>昨年くらいから、社内では自然言語処理関連のR&amp;Dやプロジェクトを進めています。私自身は、今のところ実装などの細かい部分には関わっていませんが、プロジェクトの責任者として基本的な知識は求められます。 本記事では、私 [&hellip;]</p>\n","author":{"name":"中の人（管理者）","slug":"engineering_8qmk0b","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/645c3a0bd2a9df7a7dcbb131b14267ac?s=48&d=mm&r=g"}},"dateObject":"2020-06-15T02:27:00.000Z","date":"June 15, 2020","slug":"%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%83%bb%e8%87%aa%e7%84%b6%e8%a8%80%e8%aa%9e%e5%87%a6%e7%90%86%e3%81%ae%e3%81%8a%e5%8b%a7%e3%82%81%e6%9c%ac%e3%81%aa%e3%81%a9","featured_media":{"media_details":{"sizes":{"medium":{"source_url":"https://i1.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2020/06/artificial-neural-network-3501528_1280.png?fit=300%2C169&ssl=1","height":169,"width":300}}}}}},{"node":{"id":"cc3686ef-da59-5a71-b9db-4499cf9f90e6","title":"BERTについて勉強したことまとめ (2)モデル構造について","excerpt":"<p>前回は特徴と予備知識を確認しました。今回はBERTの構造についてです。 BERTのモデルの構造 BERTのモデル構造の主な部分は、TransformerのEncoderを複数重ねただけです。それに合わせて、その上下にどの [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-06-12T12:00:00.000Z","date":"June 12, 2020","slug":"bert%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e5%8b%89%e5%bc%b7%e3%81%97%e3%81%9f%e3%81%93%e3%81%a8%e3%81%be%e3%81%a8%e3%82%81-2%e3%83%a2%e3%83%87%e3%83%ab%e6%a7%8b%e9%80%a0%e3%81%ab%e3%81%a4%e3%81%84","featured_media":null}}]}},"pageContext":{"name":"NLP","slug":"nlp"}}}