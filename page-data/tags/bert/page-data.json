{"componentChunkName":"component---src-templates-tag-js","path":"/tags/bert/","result":{"data":{"site":{"siteMetadata":{"title":"もばらぶエンジニアブログ"}},"allWordpressPost":{"totalCount":2,"edges":[{"node":{"id":"cc3686ef-da59-5a71-b9db-4499cf9f90e6","title":"BERTについて勉強したことまとめ (2)モデル構造について","excerpt":"<p>前回は特徴と予備知識を確認しました。今回はBERTの構造についてです。 BERTのモデルの構造 BERTのモデル構造の主な部分は、TransformerのEncoderを複数重ねただけです。それに合わせて、その上下にどの [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-06-12T12:00:00.000Z","date":"June 12, 2020","slug":"bert%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e5%8b%89%e5%bc%b7%e3%81%97%e3%81%9f%e3%81%93%e3%81%a8%e3%81%be%e3%81%a8%e3%82%81-2%e3%83%a2%e3%83%87%e3%83%ab%e6%a7%8b%e9%80%a0%e3%81%ab%e3%81%a4%e3%81%84","featured_media":null}},{"node":{"id":"c034aa67-9376-51a7-8b6e-5d204acccf7e","title":"BERTについて勉強したことまとめ (1) BERTとは? その特徴と解決しようとした問題、及び予備知識","excerpt":"<p>現在、社内の機械学習を用いたプロジェクトに関わっていて、その過程で学んだBERTについて今まで勉強したことをまとめてみようと思います。 自然言語処理(以下NLP)、とくにBERT周辺の理解したことを以下何回かに分けて書い [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-05-22T11:26:00.000Z","date":"May 22, 2020","slug":"bert%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e5%8b%89%e5%bc%b7%e3%81%97%e3%81%9f%e3%81%93%e3%81%a8%e3%81%be%e3%81%a8%e3%82%81-1-bert%e3%81%a8%e3%81%af-%e3%81%9d%e3%81%ae%e7%89%b9%e5%be%b4%e3%81%a8","featured_media":null}}]}},"pageContext":{"name":"BERT","slug":"bert"}}}