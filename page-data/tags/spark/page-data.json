{"componentChunkName":"component---src-templates-tag-js","path":"/tags/spark/","result":{"data":{"site":{"siteMetadata":{"title":"もばらぶエンジニアブログ"}},"allWordpressPost":{"totalCount":4,"edges":[{"node":{"id":"7ee6b83a-d7c9-5e95-b82b-8ce7d04ed671","title":"静的データベースと動的データベース（Spark SQLの小ネタ）","excerpt":"<p>このようなデータベースの種類を分ける概念は一般的にはないと思われますが、「Spark SQL」で開発しているとまさに動的だなぁという思いが湧いてくることが多々ありましたので記事にしてみました。（従来のRDBであるMySq [&hellip;]</p>\n","author":{"name":"koji","slug":"koji","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/41f316e46a0b88d22a3744ea8e162222?s=48&d=mm&r=g"}},"dateObject":"2020-09-23T03:00:00.000Z","date":"September 23, 2020","slug":"%e9%9d%99%e7%9a%84%e3%83%87%e3%83%bc%e3%82%bf%e3%83%99%e3%83%bc%e3%82%b9%e3%81%a8%e5%8b%95%e7%9a%84%e3%83%87%e3%83%bc%e3%82%bf%e3%83%99%e3%83%bc%e3%82%b9%ef%bc%88spark-sql%e3%81%ae%e5%b0%8f%e3%83%8d","featured_media":{"media_details":{"sizes":{"medium":{"source_url":"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2020/09/3892793_m.jpg?fit=300%2C212&ssl=1","height":212,"width":300}}}}}},{"node":{"id":"f8ecc913-e925-500a-b6d7-8086b9e79d43","title":"Option（Scala）の実用的な使い方 − データのマージ処理","excerpt":"<p>いまいち使いどころを理解できていなかったScalaのOptionですが、データのマージ処理を実装した際に、割と理解しやすいコードが書けたと感じましたのでざっくりとですがご紹介します。 環境 Scala 2.11.12 s [&hellip;]</p>\n","author":{"name":"koji","slug":"koji","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/41f316e46a0b88d22a3744ea8e162222?s=48&d=mm&r=g"}},"dateObject":"2019-10-24T00:00:27.000Z","date":"October 24, 2019","slug":"option%ef%bc%88scala%ef%bc%89%e3%81%ae%e5%ae%9f%e7%94%a8%e7%9a%84%e3%81%aa%e4%bd%bf%e3%81%84%e6%96%b9-%e2%88%92-%e3%83%87%e3%83%bc%e3%82%bf%e3%81%ae%e3%83%9e%e3%83%bc%e3%82%b8%e5%87%a6%e7%90%86","featured_media":{"media_details":{"sizes":{"medium":{"source_url":"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/10/Screen-Shot-2019-10-23-at-17.48.40.png?fit=300%2C53&ssl=1","height":53,"width":300}}}}}},{"node":{"id":"8cc962b4-6e34-529e-a13a-ebc98f841ffb","title":"Elasticsearch for Apache Hadoopを使ってSparkからAmazon ESにデータと連携してみた","excerpt":"<p>今とあるプロジェクトで、Amazon EMRを使って少し大きめなボリュームのデータ処理をしているのですが、その中のあるデータの中身をWebフォームからニアリアルタイムでフィルタリングしたいと言う要望があり、その基盤として [&hellip;]</p>\n","author":{"name":"issei_m","slug":"issei","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/5507488fbe666087f0136a52985101d7?s=48&d=mm&r=g"}},"dateObject":"2019-06-17T10:59:12.000Z","date":"June 17, 2019","slug":"trying-elasticsearch-apache-hadoop-integration","featured_media":{"media_details":{"sizes":{"medium":{"source_url":"https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/es_spark.png?fit=300%2C120&ssl=1","height":120,"width":300}}}}}},{"node":{"id":"e81c4703-55ce-500d-90a9-7f888c2bf9fb","title":"Spark の DataFrame のテスト","excerpt":"<p>はじめに Apache Spark では、御存知の通り大規模なデータを高速に扱う事が出来ます。大規模データ処理のインフラという観点では、速度のチューニングのために、データ構造を調整したりデータ処理の順番を最適化したりとい [&hellip;]</p>\n","author":{"name":"中の人（管理者）","slug":"engineering_8qmk0b","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/645c3a0bd2a9df7a7dcbb131b14267ac?s=48&d=mm&r=g"}},"dateObject":"2018-07-23T01:59:55.000Z","date":"July 23, 2018","slug":"testing-spark-dataframe","featured_media":{"media_details":{"sizes":{"medium":{"source_url":"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2018/07/hook-1425312_1000.jpg?fit=300%2C180&ssl=1","height":180,"width":300}}}}}}]}},"pageContext":{"name":"Spark","slug":"spark"}}}