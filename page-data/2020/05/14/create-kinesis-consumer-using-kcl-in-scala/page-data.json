{"componentChunkName":"component---src-templates-post-js","path":"/2020/05/14/create-kinesis-consumer-using-kcl-in-scala/","result":{"data":{"wordpressPost":{"id":"d0441fba-7510-56f8-9152-acb0975e74fa","title":"Scala + Kinesis Client LibraryでKinesisコンシューマーアプリケーションを作る","excerpt":"<p>ここ最近のプロジェクトでKinesisのコンシューマーアプリケーションをScalaで開発・メンテしていたので、何回かに分けてノウハウをメモしておきます。 今回はScalaでKinesis Client Libraryを使 [&hellip;]</p>\n","slug":"create-kinesis-consumer-using-kcl-in-scala","content":"\n<p>ここ最近のプロジェクトでKinesisのコンシューマーアプリケーションをScalaで開発・メンテしていたので、何回かに分けてノウハウをメモしておきます。</p>\n\n\n\n<p>今回はScalaでKinesis Client Libraryを使って、ストリームのコンシューマアプリケーション実装した内容を簡単に記載します。尚、今回採用したKinesis Client Libraryのバージョンは1.x系となります。</p>\n\n\n\n<h2 id=\"Kinesisデータストリームについてざっくり\">Kinesisデータストリームについてざっくり</h2>\n\n\n\n<p>AWSによるスケーラブルなフルマネージドのデータストリームサービスで、ログやユーザーアクティビティ等、大量のデータレコードをリアルタイムに処理する事ができます。類似サービスにApache Kafka等があります。<br>Amazon SQSのようなキューサービスとの違いは、コンシューマーがどこまでデータを処理したかをストリーム側が管理しないと言う点です。一度ストリームに投下されたデータは一定期間保管され、その間はいつでも取得する事が可能です。</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://i2.wp.com/engineering.mobalab.net/wp-content/uploads/2020/05/V9LCiUs.png?fit=1024%2C440&amp;ssl=1\" alt=\"\" class=\"wp-image-1471\" srcset=\"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2020/05/V9LCiUs.png?w=1102&amp;ssl=1 1102w, https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2020/05/V9LCiUs.png?resize=300%2C129&amp;ssl=1 300w, https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2020/05/V9LCiUs.png?resize=1024%2C440&amp;ssl=1 1024w, https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2020/05/V9LCiUs.png?resize=768%2C330&amp;ssl=1 768w\" sizes=\"(max-width: 1102px) 100vw, 1102px\" /><figcaption>Kinesisデータストリームのイメージ図</figcaption></figure>\n\n\n\n<p>また、シャード単位で水平分割する事で、データ量に応じていつでも簡単にスケールイン・アウトする事ができます。<br>詳しくは<a rel=\"noreferrer noopener\" href=\"https://aws.amazon.com/jp/kinesis/\" target=\"_blank\">Amazon Kinesis</a>を参照。</p>\n\n\n\n<h2 id=\"Kinesis-Client-Library-以下KCL-について\">Kinesis Client Library (以下KCL) について</h2>\n\n\n\n<p><a href=\"https://github.com/awslabs/amazon-kinesis-client\">https://github.com/awslabs/amazon-kinesis-client</a></p>\n\n\n\n<p>AWSが公式で公開している、Kinesisのコンシューマーアプリケーションを容易に実装する為のライブラリです。<br>Kinesisも例外なくAPIが公開されているので自前でそれらを駆使して実装する事は可能ですが、Kinesisのコンシューマーアプリケーションは考慮すべき点が膨大にある為、よほどの理由がない限りはKCLを使うようにしましょう。</p>\n\n\n\n<p>対応言語はJavaなのでScalaでも使えます。一応、他の言語（Node.jsやRuby, Python）にも展開されていますが、実質的にJVMで動くKCL Daemonを経由する事になるので、JVM言語を使うのが簡単です。</p>\n\n\n\n<h3 id=\"KCLを使うメリット\">KCLを使うメリット</h3>\n\n\n\n<p>先程も言ったとおりKinesisデータストリームはシャード単位で水平分割するのですが、その場合当然ながらコンシューマアプリケーション側も分割して動作する必要があります。<br>KCLを実装したJVMアプリケーションは、シャードの増減に応じてワーカーをスレッド単位で自動的に増減する事で、均等に処理を割り振る事が可能です。<br>また、コンシューマアプリケーションを実行するプロセスを増やしたり、あるいは実行インスタンスそのものが新たに起動、または停止すると、それぞれのインスタンス上のワーカー同士がよしなに割り当てを譲り合う事で、マシンのスケールアウト・インが容易に可能となっています。</p>\n\n\n\n<p>また、その他にもシャード毎に処理したレコード数や遅延ミリ秒等の統計情報をCloudWatchに送信してくれる等の面倒も見てくたりと大変便利です。</p>\n\n\n\n<h2 id=\"KCLの実装の基本\">KCLの実装の基本</h2>\n\n\n\n<p>主な作業は、Javaで提供されているインターフェース&nbsp;<code>IRecordProcessor</code>&nbsp;を実装する事です。これはレコードプロセッサと呼ばれ、ワーカーの実態となります。1つのレコードプロセッサは1つのシャードに割り当てられます。シャードが10個ある場合、レコードプロセッサも10個立ち上がります。<br>このインターフェースに定義されているメソッドを具体的に実装するのですが、アプリケーションのユースケースによっていくつか注意しないといけない点があります。</p>\n\n\n<pre class=\"brush: java; title: ; notranslate\" title=\"\">\npublic interface IRecordProcessor {\n    void initialize(InitializationInput initializationInput);\n    void processRecords(ProcessRecordsInput processRecordsInput);\n    void shutdown(ShutdownInput shutdownInput);\n}\n</pre>\n\n\n<h4 id=\"initialize\">initialize</h4>\n\n\n\n<p>レコードプロセッサが初期化されると実行されます。タイミングとしては最初にアプリケーションを起動した時や、シャードが増加、または実行インスタンスが増加した際に新しく割り当てが起きた場合等です。&nbsp;<code>InitializationInput</code>&nbsp;から割り当てられたシャードのID等を取得する事ができます。</p>\n\n\n\n<p>Scalaでの実装例:</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nclass RecordProcessor extends IRecordProcessor {\n\n  override def initialize(initializationInput: InitializationInput): Unit = {\n    shardId = initializationInput.getShardId\n\n    println(s&quot;Initialized processor for $shardId&quot;)\n  }\n  \n  // ...\n  \n}\n</pre>\n\n\n<h4 id=\"processRecords0\">processRecords</h4>\n\n\n\n<p>Kinesisストリームからレコードを受け取ると実行されます。アプリケーションが遅延なく正常にストリームを消費している場合、ストリームにデータがPushされるとすぐに実行されます。<br>また、ここではあまり深く触れませんが、同じくAWSから提供されているKinesis Producer Libraryと言う、Kinesisにデータを投入する為のライブラリでは、複数のレコードを可能な限り単一のレコードに集約して処理するので、コンシューマ側の責務としてこの集約の解除を行わないといけないのですが、KCLではこの処理も自動的に行なってくれます。</p>\n\n\n\n<p><code>ProcessRecordsInput</code>&nbsp;から受信した全てのレコードをList形式で取り出す事ができるので、後はアプリケーション側でレコードを処理するだけとなります。</p>\n\n\n\n<p>Scalaでの実装例:</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nclass RecordProcessor extends IRecordProcessor {\n  \n  // ...\n  \n  override def processRecords(processRecordsInput: ProcessRecordsInput): Unit = {\n    val records = processRecordsInput.getRecords.asScala\n\n    println(s&quot;Processing ${records.length} records, ${processRecordsInput.getMillisBehindLatest} msec behind latest&quot;)\n\n    records.foreach { record =&gt;\n      // ...\n    }\n  }\n  \n  // ...\n\n}\n</pre>\n\n\n<h4 id=\"shutdown\">shutdown</h4>\n\n\n\n<p>その名の通り、レコードプロセッサが終了する時に呼ばれ、主に<strong>後述するチェックポイント処理</strong>の為に使います。<br><code>ShutdownInput</code>&nbsp;からはシャットダウンの理由を知る事ができます。シャットダウンの理由は2つあります:</p>\n\n\n\n<ul><li class=\"\">シャードの割り当てが別のプロセッサに移った時（他のインスタンスにスケールアウト、あるいはフェイルオーバーする際）</li><li class=\"\">割り当てれているシャードが、リシャーディングにより終了した時</li></ul>\n\n\n\n<p>それとは別に、KCLアプリケーションのプロセスが終了した事を検知するフックもあるのですが、そちらも後述します。</p>\n\n\n\n<h2 id=\"チェックポイントについて\">チェックポイントについて</h2>\n\n\n\n<p>先述したとおり、Kinesisストリームは、コンシューマがどこまでデータを読み込んだかを管理しません。その代わりに、読み出しを開始するポイントをピンポイントに指定ができますので、アプリケーション側でどこまで読み込んだかを記録しておく必要があります。</p>\n\n\n\n<p>KCLはチェックポイントをDynamoDB駆動で簡単に記録できる仕組みも用意されていて、これを使う事ができます。<br>ただし、チェックポイント記録の戦略はアプリケーションのニーズによって異なる為か、自動的には行われません。従って、処理は自前で実装する必要がありますが、&nbsp;<code>IRecordProcessor</code>&nbsp;のメソッド引数では簡単にチェックポイント記録が行えるようになっています。</p>\n\n\n\n<h4 id=\"チェックポイント処理の共通化\">チェックポイント処理の共通化</h4>\n\n\n\n<p>チェックポイントの記録処理はDynamoDBを介して行われる為、書き込みスループット上昇時のスロットリングエラーに対処する必要があります。今回は、以下のようにDynamoDBへの過去込み失敗時には一定期間を置いてリトライする仕組みを準備しました:</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nclass RecordProcessor extends IRecordProcessor {\n\n  private val CHECKPOINT_RETRY_COUNT = 10\n  \n  // ...\n\n  @scala.annotation.tailrec\n  private def retryable(retryCount: Int)(f: =&gt; Unit): Unit = {\n    try f\n    catch {\n      case e: Throwable =&gt;\n        if (retryCount &gt; 0) {\n          println(s&quot;An error occurred, will be retried at most $retryCount time(s)...&quot;, e)\n\n          try Thread.sleep(3000)\n          catch {\n            case e: InterruptedException =&gt; println(&quot;Interrupted sleep&quot;, e)\n          }\n\n          retryable(retryCount - 1)(f)\n        } else {\n          println(s&quot;An error occurred&quot;, e)\n        }\n    }\n  }\n  \n  private def checkpoint(checkpointer: IRecordProcessorCheckpointer): Unit =\n    retryable(CHECKPOINT_RETRY_COUNT) {\n      checkpointer.checkpoint()\n    }\n}\n</pre>\n\n\n<p>チェックポイントを記録する際は、&nbsp;<code>checkpoint</code>&nbsp;メソッドにチェックポインタ（各インターフェースメソッドで取り出せる）を渡す必要があります。</p>\n\n\n\n<h4 id=\"processRecords\">processRecords</h4>\n\n\n\n<p>まずは、&nbsp;<code>processRecords</code>&nbsp;の実装を次のようにします:</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nclass RecordProcessor extends IRecordProcessor {\n\n  private val CHECKPOINT_INTERVAL_MILLIS = 30000L\n  private var nextCheckpointTimeInMillis = 0L\n  \n  // ...\n\n  override def processRecords(processRecordsInput: ProcessRecordsInput): Unit = {\n    val records = processRecordsInput.getRecords.asScala\n\n    println(s&quot;Processing ${records.length} records, ${processRecordsInput.getMillisBehindLatest} msec behind latest&quot;)\n\n    records.foreach { record =&gt;\n      // ...\n    }\n\n    // チェックポイント処理. DateTimeは `org.joda.time.DateTime` \n    if (DateTime.now().getMillis &gt; nextCheckpointTimeInMillis) {\n      checkpoint(processRecordsInput.getCheckpointer)\n\n      nextCheckpointTimeInMillis = DateTime.now().getMillis + CHECKPOINT_INTERVAL_MILLIS\n    }\n  }\n  \n  // ...\n}\n</pre>\n\n\n<p>先程のprocessRecordsのサンプルに処理を追加しました。今回のポイントとしては以下の2点です:</p>\n\n\n\n<ul><li class=\"\">全てのレコードが正常に処理された場合のみチェックポイントを記録している<ul><li class=\"\">処理中に例外が発生した場合は記録を行わない</li></ul></li><li class=\"\">30秒以内に次のprocessRecordsが実行された際は記録は行わない<ul><li class=\"\">DynamoDBのスロットリング軽減の為</li></ul></li></ul>\n\n\n\n<p>ただし、これが正解と言うわけではありません。先述の通り、チェックポイントの戦略は多種多様です。例えば、全てのレコード (<code>processRecordsInput.getRecords</code>&nbsp;の要素) はシーケンスナンバーを保持しており、これをチェックポインタにわたす事で、ピンポイントにそのレコードまでを記録する事が可能です。</p>\n\n\n\n<p>以下はシンプルな一例です (※今回はこの戦略を採用していないので自前実装した&nbsp;<code>checkpoiot</code>&nbsp;は使ってません):</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nvar lastSequenceNumber = &quot;&quot;\n\nrecords.foreach { record =&gt;\n  try {\n    // ...\n\n    lastSequenceNumber = record.getSequenceNumber\n  }\n  catch {\n    case e: Throable =&gt; {\n      if (lastSequenceNumber.nonEmpty) \n        processRecordsInput.getCheckpointer.checkpoint(lastSequenceNumber)\n\n      throw e\n    }\n  }\n}\n\nif (lastSequenceNumber.nonEmpty) \n  processRecordsInput.getCheckpointer.checkpoint(lastSequenceNumber)\n</pre>\n\n\n<p>レコード処理で例外が発生した時点で、正常に処理できた最後のチェックポイントを記録しています。</p>\n\n\n\n<h4 id=\"shutdown1\">shutdown</h4>\n\n\n\n<p>さて、先程<a href=\"#shutdown\">ちらっと書きました</a>が、チェックポイントの記録は&nbsp;<code>shutdown</code>&nbsp;時にも行う事ができます。<br>以下に例を示します:</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nclass RecordProcessor extends IRecordProcessor {\n\n  // ...\n\n  override def shutdown(shutdownInput: ShutdownInput): Unit = {\n    println(s&quot;Shutdown processor, reason: ${shutdownInput.getShutdownReason}&quot;)\n\n    // シャットダウンの理由が &quot;TERMINATE&quot; の時だけ書き込み\n    if (shutdownInput.getShutdownReason == ShutdownReason.TERMINATE) {\n      checkpoint(shutdownInput.getCheckpointer)\n    }\n  }\n}\n</pre>\n\n\n<p><code>shutdown</code>&nbsp;はレコードプロセッサが主に<a href=\"https://hackmd.io/iN8J0hLcRBSyacAOZwjoDA?view#shutdown\">2つの理由で閉じられる時</a>にコールされますが、その内の理由が&nbsp;<code>TERMINATE</code>&nbsp;の時だけチェックポイントを記録します。<br><code>TERMINATE</code>&nbsp;はリシャーディングにより、割り当てられたシャードの全てのレコードを処理した時に呼ばれます。KCLアプリケーションでは、リシャーディング時に作られた新しいシャードへは、この終了するシャードのチェックポイントが記録されるまでレコードプロセッサが割り当てられないので、必ずこの処理は実装する必要があります。</p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p>For a split or merge operation, the KCL won’t start processing the new shards until the processors for the original shards have called checkpoint to signal that all processing on the original shards is complete.</p><cite>https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-implementation-app-java.html#kinesis-record-processor-implementation-interface-java</cite></blockquote>\n\n\n\n<p>反対にもう1つの理由である&nbsp;<code>ZOMBIE</code>&nbsp;の時はチェックポイントの記録は行ってはいけません。この理由でプロセッサが閉じられるのは、スケールアウト、またはフェイルオーバーにより他のプロセッサにシャードの割り当てが奪われるケースであり、すでに新しいプロセッサがレコードの処理を開始している可能性がある為です。</p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p>Applications SHOULD NOT checkpoint their progress (as another record processor may have already started processing data).</p><cite>https://github.com/awslabs/amazon-kinesis-client/blob/8873b1346ff033de01fa1a237c0436d8fb762d9a/amazon-kinesis-client/src/main/java/software/amazon/kinesis/lifecycle/ShutdownReason.java#L36-L37</cite></blockquote>\n\n\n\n<h5 id=\"shutdownRequested\">shutdownRequested</h5>\n\n\n\n<p>さて、KCLにはワーカーそのものが終了する事による、レコードプロセッサの終了処理を作る事もできます。通常、Kinesisストリームのコンシューマーは24/7で稼働するのでワーカーが終了する事はまれですが、ユースケースとして必要であればここでもチェックポイントを記録できます。</p>\n\n\n\n<p>まず、レコードプロセッサ自体に&nbsp;<code>IShutdownNotificationAware</code>&nbsp;インターフェースを実装します。このインターフェースは単一の&nbsp;<code>shutdownRequested</code>&nbsp;メソッドを提供します:</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nclass RecordProcessor extends IRecordProcessor with IShutdownNotificationAware {\n\n  // ...\n\n  override def shutdownRequested(checkpointer: IRecordProcessorCheckpointer): Unit = {\n    println(&quot;Shutdown processor requested&quot;)\n\n    checkpoint(checkpointer)\n  }\n  \n  // ...\n}\n</pre>\n\n\n<h2 id=\"エントリポイントの実装\">エントリポイントの実装</h2>\n\n\n\n<p>最後に、エントリポイントとなるメインクラスを準備すればOKです。</p>\n\n\n<pre class=\"brush: scala; title: ; notranslate\" title=\"\">\nobject MyConsumer extends App \n\n  val workerId = s&quot;${InetAddress.getLocalHost.getCanonicalHostName}:${UUID.randomUUID}&quot;\n  val credentialsProvider = InstanceProfileCredentialsProvider.getInstance()\n  val region = Regions.getCurrentRegion\n  val kclConf = new KinesisClientLibConfiguration(cfg.kclApplicationName, cfg.kclStreamName, credentialsProvider, workerId)\n    .withInitialPositionInStream(InitialPositionInStream.TRIM_HORIZON)\n    .withRegionName(region)\n\n  val recordProcessorFactory = new IRecordProcessorFactory {\n    override def createProcessor: IRecordProcessor = new RecordProcessor()\n  }\n\n  val worker = new Worker.Builder()\n    .recordProcessorFactory(recordProcessorFactory)\n    .config(kclConf)\n    .build()\n\n  // Javaプロセスの終了を検出し、ワーカーを安全にシャットダウンする. ただし90秒以内に終了できなければ強制終了とする.\n  // レコードプロセッサの `requestedShutdown` が呼ばれる.\n  sys.addShutdownHook {\n    info(&quot;Shutting down...&quot;)\n\n    try {\n      Await.result(\n        Future(worker.startGracefulShutdown().get()),\n        Duration(90, SECONDS)\n      )\n    } catch {\n      case _: TimeoutException =&gt; println(&quot;Shutdown duration timed out&quot;)\n    }\n  }\n\n  worker.run()\n</pre>\n\n\n<p>InitialPositionについては、これもユースケースによるのですが、今回は極力取りこぼしをなくす為にTRIM_HORIZONにしました。また、今回はワーカーを安全にシャットダウンできるようにJavaのシャットダウンフックを利用しています。</p>\n\n\n\n<h2 id=\"運用について\">運用について</h2>\n\n\n\n<p>運用面でも色々学びが多かったのですが、それはまた後日別に書く事にします。</p>\n","dateObject":"2020-05-14T02:32:19.000Z","date":"May 14, 2020","categories":[{"name":"Uncategorized","slug":"uncategorized"}],"tags":[{"name":"AWS","slug":"aws"},{"name":"KCL","slug":"kcl"},{"name":"Kinesis","slug":"kinesis"},{"name":"Scala","slug":"scala"}],"author":{"name":"issei_m","slug":"issei"},"featured_media":{"media_details":{"sizes":{"large":null,"medium_large":null}},"source_url":"https://stg-engineering-wp.mobalab.net/wp-content/uploads/2020/05/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f302a5551424b6a4566663175497358483857.png"},"wordpress_id":1469}},"pageContext":{"id":"d0441fba-7510-56f8-9152-acb0975e74fa","nextPath":"/2020/05/12/rails-app-in-docker-on-azure-app-service/","nextTitle":"Azure App Service + Docker で Rails アプリを動かす","prevPath":"/2020/05/21/how-to-deal-with-non-24-7-kcl-consumer/","prevTitle":"24時間稼働でないKinesisストリームの運用で手こずった点"}}}