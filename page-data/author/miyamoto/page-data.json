{"componentChunkName":"component---src-templates-author-js","path":"/author/miyamoto","result":{"data":{"site":{"siteMetadata":{"title":"もばらぶエンジニアブログ"}},"wordpressWpUsers":{"name":"miyamonz","authored_wordpress__POST":[{"id":"7960fddf-4cac-5842-be72-4a10ab864ba7","title":"kedro触ってみた","excerpt":"<p>PyTorchで学習周りのコードを書いてたのですが、今後も検証を勧めていく上で、実験結果の記録やパラメータ変更や複数モデルの比較などをするために、何らかの学習周りのコードを扱うフレームワークを利用しようと思っていました。 [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-09-17T00:00:00.000Z","date":"September 17, 2020","slug":"kedro%e8%a7%a6%e3%81%a3%e3%81%a6%e3%81%bf%e3%81%9f","featured_media":null},{"id":"19d3cd0a-0ed8-5492-b5c6-abb026424062","title":"BERTについて勉強したことまとめ (3) 自己教師学習と汎用性について","excerpt":"<p>前回の続きです。今回はBERTにおける２つのトピック、自己教師学習と汎用性についてです。 自己教師学習 アノテーション 機械学習において、教師ありデータというものの多くは、人間が手動でラベル付をします。例えば犬の画像から [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-09-16T00:00:00.000Z","date":"September 16, 2020","slug":"bert%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e5%8b%89%e5%bc%b7%e3%81%97%e3%81%9f%e3%81%93%e3%81%a8%e3%81%be%e3%81%a8%e3%82%81-3-%e8%87%aa%e5%b7%b1%e6%95%99%e5%b8%ab%e5%ad%a6%e7%bf%92%e3%81%a8%e6%b1%8e","featured_media":null},{"id":"cc3686ef-da59-5a71-b9db-4499cf9f90e6","title":"BERTについて勉強したことまとめ (2)モデル構造について","excerpt":"<p>前回は特徴と予備知識を確認しました。今回はBERTの構造についてです。 BERTのモデルの構造 BERTのモデル構造の主な部分は、TransformerのEncoderを複数重ねただけです。それに合わせて、その上下にどの [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-06-12T12:00:00.000Z","date":"June 12, 2020","slug":"bert%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e5%8b%89%e5%bc%b7%e3%81%97%e3%81%9f%e3%81%93%e3%81%a8%e3%81%be%e3%81%a8%e3%82%81-2%e3%83%a2%e3%83%87%e3%83%ab%e6%a7%8b%e9%80%a0%e3%81%ab%e3%81%a4%e3%81%84","featured_media":null},{"id":"c034aa67-9376-51a7-8b6e-5d204acccf7e","title":"BERTについて勉強したことまとめ (1) BERTとは? その特徴と解決しようとした問題、及び予備知識","excerpt":"<p>現在、社内の機械学習を用いたプロジェクトに関わっていて、その過程で学んだBERTについて今まで勉強したことをまとめてみようと思います。 自然言語処理(以下NLP)、とくにBERT周辺の理解したことを以下何回かに分けて書い [&hellip;]</p>\n","author":{"name":"miyamonz","slug":"miyamoto","avatar_urls":{"wordpress_48":"https://secure.gravatar.com/avatar/203b850b2dab54bf7f554e04762e57df?s=48&d=mm&r=g"}},"dateObject":"2020-05-22T11:26:00.000Z","date":"May 22, 2020","slug":"bert%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e5%8b%89%e5%bc%b7%e3%81%97%e3%81%9f%e3%81%93%e3%81%a8%e3%81%be%e3%81%a8%e3%82%81-1-bert%e3%81%a8%e3%81%af-%e3%81%9d%e3%81%ae%e7%89%b9%e5%be%b4%e3%81%a8","featured_media":null}]}},"pageContext":{"id":"2ebecbce-77ed-587c-bab8-d70dca00e6b8"}}}