{"componentChunkName":"component---src-templates-post-js","path":"/2019/06/17/trying-elasticsearch-apache-hadoop-integration/","result":{"data":{"wordpressPost":{"id":"8cc962b4-6e34-529e-a13a-ebc98f841ffb","title":"Elasticsearch for Apache Hadoopを使ってSparkからAmazon ESにデータと連携してみた","excerpt":"<p>今とあるプロジェクトで、Amazon EMRを使って少し大きめなボリュームのデータ処理をしているのですが、その中のあるデータの中身をWebフォームからニアリアルタイムでフィルタリングしたいと言う要望があり、その基盤として [&hellip;]</p>\n","slug":"trying-elasticsearch-apache-hadoop-integration","content":"\n<p>今とあるプロジェクトで、Amazon EMRを使って少し大きめなボリュームのデータ処理をしているのですが、その中のあるデータの中身をWebフォームからニアリアルタイムでフィルタリングしたいと言う要望があり、その基盤としてElasticsearchを採用する事にしました。</p>\n\n\n\n<p>前提としては、ざっくり言うと以下のような環境です:</p>\n\n\n\n<ul><li class=\"\">対象データの総ボリュームは5.5億レコード<ul><li class=\"\">ただし特定フィールドで集計を行うので、Elasticsearchに入れるルートドキュメントの数でいうと3000万程度</li></ul></li><li class=\"\">データの更新頻度は1日に1度<ul><li class=\"\">極端に言えば24時間以内に処理が終わればOKと言う事</li></ul></li><li class=\"\">データの更新とは別で、1日に1度、予め保存したクエリ条件にマッチするレコードをParquetで書き込むと言う要件もある</li><li class=\"\">ElasticsearchはVPC内のAmazon ES (Elasticsearch Service) 管理のドメインを使用<ul><li class=\"\">ロードバランサー越しにしか通信できない</li><li class=\"\">プロビジョンしたElasticsearchのバージョンは執筆時点で最新版の6.7</li></ul></li></ul>\n\n\n\n<h2 id=\"Elasticsearchについて\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#Elasticsearch%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"></a>Elasticsearchについて</h2>\n\n\n\n<p>データの投入方法以前に、ユースケースとして事前に想定ボリューム数で検証した結果、Elasticsearchであれば（ボリューム的に当然ですが）問題なく検索が可能と言う事が分かったので事前に決定していました。</p>\n\n\n\n<p>クラスタは先述の通りAmazon ESで管理されています。</p>\n\n\n\n<h2 id=\"Sparkについて\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#Spark%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"></a>Sparkについて</h2>\n\n\n\n<p>投入方法については先述の要件が満たせれば何でも良かったのですが、色々試した結果、そもそもEMRでのデータ処理自体にも使っていた事もあって、Sparkが良さそうと言う事になり、これに決定しました。</p>\n\n\n\n<p>また、今回双方の連携にはElasticsearchが提供している<a href=\"https://www.elastic.co/guide/en/elasticsearch/hadoop/6.7/reference.html\" target=\"_blank\" rel=\"noreferrer noopener\">Elasticsearch for Apache Hadoop</a>と言うインテグレーションライブラリを使いました。<br>SparkとElasticsearchを連携する為のAPIがJARアーカイブにまとめられており、&nbsp;<a href=\"https://www.elastic.co/jp/downloads/hadoop\" target=\"_blank\" rel=\"noreferrer noopener\">ここ</a>からダウンロードが可能です。</p>\n\n\n\n<p>なお、今回はAmazon ESのバージョンが執筆時点で最新である6.7なので、それにあわせ、<a rel=\"noreferrer noopener\" href=\"https://www.elastic.co/jp/downloads/past-releases/elasticsearch-apache-hadoop-6-7-2\" target=\"_blank\">Elasticsearch for Apache Hadoop 6.7.2</a>を使いました。</p>\n\n\n\n<p>※実際のアプリケーションではbuild.sbtとかで依存管理をしますが今回はテストなので直接👆のjarを使います。<br>※Maven Repositoryのページは:&nbsp;<a href=\"https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-hadoop/6.7.2\" target=\"_blank\" rel=\"noreferrer noopener\">https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-hadoop/6.7.2</a></p>\n\n\n\n<h2 id=\"試してみる\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#%E8%A9%A6%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B\"></a>試してみる</h2>\n\n\n\n<p>事前に、先程👆でダウンロードしたJARをS3の適当なバケットにアップロードしておきます。</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/jar.png?w=1200&#038;ssl=1\" alt=\"\" class=\"wp-image-949\" srcset=\"https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/jar.png?w=641&amp;ssl=1 641w, https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/jar.png?resize=300%2C285&amp;ssl=1 300w\" sizes=\"(max-width: 641px) 100vw, 641px\" data-recalc-dims=\"1\" /><figcaption>elasticsearch-hadoop-6.7.2.jar</figcaption></figure>\n\n\n\n<p>その後、EMRで適当にSparkのクラスタを作成します。こちらも執筆時点で最新版の “Spark 2.4.0 on Hadoop 2.8.5 YARN with Ganglia 3.7.2 and Zeppelin 0.8.1” を選択しています:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-registration.png?w=1200&#038;ssl=1\" alt=\"\" class=\"wp-image-950\" srcset=\"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-registration.png?w=689&amp;ssl=1 689w, https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-registration.png?resize=300%2C153&amp;ssl=1 300w\" sizes=\"(max-width: 689px) 100vw, 689px\" data-recalc-dims=\"1\" /><figcaption>EMRクラスタ作成画面</figcaption></figure>\n\n\n\n<p>クラスタがReadyになったら、SSHでログインします:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-console.png?w=1200&#038;ssl=1\" alt=\"\" class=\"wp-image-951\" srcset=\"https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-console.png?w=776&amp;ssl=1 776w, https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-console.png?resize=300%2C186&amp;ssl=1 300w, https://i0.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/emr-console.png?resize=768%2C476&amp;ssl=1 768w\" sizes=\"(max-width: 776px) 100vw, 776px\" data-recalc-dims=\"1\" /></figure>\n\n\n\n<p>早速spark-shellを起動します。この時、先程用意したJARといくつかのオプションを設定しておきます:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\n$ spark-shell --jars s3://YOUR-BUCKET/elasticsearch-hadoop-6.7.2.jar \\\n  --conf spark.es.nodes=vpc-my-es-xxxxxxxxxxxxxxxxxxxxxxx.us-west-2.es.amazonaws.com \\\n  --conf spark.es.port=80 \\\n  --conf spark.es.nodes.wan.only=true\n</pre>\n\n\n<p>Elasticsearch for Apache Hadoopでは、<code>spark-shell</code>&nbsp;または&nbsp;<code>spark-submit</code>&nbsp;時に&nbsp;<code>spark.</code>&nbsp;接頭辞を付ける事で、インテグレーションAPIの設定を指定する事ができます。<br>例えば&nbsp;<code>spark.es.nodes</code>&nbsp;は&nbsp;<code>es.nodes</code>&nbsp;と言うkeyで設定が行われます。（設定の一覧については<a href=\"https://www.elastic.co/guide/en/elasticsearch/hadoop/6.7/configuration.html\" target=\"_blank\" rel=\"noreferrer noopener\">公式ドキュメント</a>を参照の事）</p>\n\n\n\n<p>上記の3つの設定ですが、執筆時点ではAmazon ESとの疎通では必須となる設定です。Amazon ESで管理されているノードは直接エンドポイントが公開されず、通信には全て&nbsp;<code>vpc-hogehoge-xxxxxxxxxxxxxxxxxxxxxxx.us-west-2.es.amazonaws.com</code>&nbsp;のようなドメインのロードバランサーを経由する必要があります。<br>また、ポートについてもデフォルトの9200ではなく80が使われてるので、指定しておく必要があります。<br>最後の&nbsp;<code>es.nodes.wan.only</code>&nbsp;ですが、このAPIがデフォルトの挙動として、各ノードと個別にやり取りをする事で効率化を図ろうとする挙動（Node Discovery）となっているのですが、先述の通りAmazon ESではそれが行えないので、この設定で&nbsp;<code>true</code>&nbsp;を明示しておかないとエラーが発生します。</p>\n\n\n\n<p>尚、設定はSparkアプリケーションを起動後も個別に設定を指定する事ができます（後述）が、こう言う基本的な設定は起動時に設定しても良いでしょう。</p>\n\n\n\n<p>さて、先程の&nbsp;<code>spark-shell</code>&nbsp;が成功すると、以下のようにreplが起動します:</p>\n\n\n\n<figure class=\"wp-block-image\"><img src=\"https://i0.wp.com/engineering.mobalab.net/wp-content/uploads/2019/06/repl.png?fit=680%2C246&amp;ssl=1\" alt=\"\" class=\"wp-image-952\" srcset=\"https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/repl.png?w=1660&amp;ssl=1 1660w, https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/repl.png?resize=300%2C109&amp;ssl=1 300w, https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/repl.png?resize=768%2C279&amp;ssl=1 768w, https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/repl.png?resize=1024%2C371&amp;ssl=1 1024w\" sizes=\"(max-width: 1200px) 100vw, 1200px\" /></figure>\n\n\n\n<h3 id=\"データを書き込んでみる\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E6%9B%B8%E3%81%8D%E8%BE%BC%E3%82%93%E3%81%A7%E3%81%BF%E3%82%8B\"></a>データを書き込んでみる</h3>\n\n\n\n<p>早速、次のコマンドを実行してみましょう:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\nscala&gt; import org.elasticsearch.spark._\n\nscala&gt; val inputData = Seq( Map(&quot;id&quot; -&gt; &quot;1&quot;, &quot;name&quot; -&gt; &quot;Alice&quot;), Map(&quot;id&quot; -&gt; &quot;2&quot;, &quot;name&quot; -&gt; &quot;Britney&quot;) )\ninputData: Seq[scala.collection.immutable.Map[String,String]] = List(Map(id -&gt; 1, name -&gt; Alice), Map(id -&gt; 2, name -&gt; Britney))\n\nscala&gt; sc.makeRDD(inputData).saveToEs(&quot;test-index/_doc&quot;)\n</pre>\n\n\n<p>これは、以下を実行しています:</p>\n\n\n\n<ul><li class=\"\">1行目の&nbsp;<code>import org.elasticsearch.spark._</code>&nbsp;を import する事で、デフォルトのSparkContextを拡張し、<code>saveToEs</code>&nbsp;メソッドが実行できるようにしています<ul><li class=\"\"><code>org.elasticsearch.spark.rdd.EsSpark.saveToEs(rdd, indexName)</code>&nbsp;ともできます</li></ul></li><li class=\"\">2行目で入力用JSONデータの作成</li><li class=\"\">3行目でデータをRDD化し、そのままElastcsearchのインデクス&nbsp;<code>test-index</code>&nbsp;のタイプ&nbsp;<code>_doc</code>に保存しています</li></ul>\n\n\n\n<p>これで、2行のレコードが追加されました。別ターミナルでレコードを確認してみましょう:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\n$ curl vpc-my-es-xxxxxxxxxxxxxxxxxxxxxxx.us-west-2.es.amazonaws.com/test-index/_search?pretty\n{\n  ...,\n  &quot;hits&quot; : {\n    ...,\n    &quot;hits&quot; : [\n      {\n        &quot;_index&quot; : &quot;test-index&quot;,\n        &quot;_type&quot; : &quot;_doc&quot;,\n        &quot;_id&quot; : &quot;1aHaYGsB-_mWDM_3fLJ-&quot;,\n        &quot;_score&quot; : 1.0,\n        &quot;_source&quot; : {\n          &quot;id&quot; : &quot;1&quot;,\n          &quot;name&quot; : &quot;Alice&quot;\n        }\n      },\n      {\n        &quot;_index&quot; : &quot;test-index&quot;,\n        &quot;_type&quot; : &quot;_doc&quot;,\n        &quot;_id&quot; : &quot;1qHaYGsB-_mWDM_3gLJb&quot;,\n        &quot;_score&quot; : 1.0,\n        &quot;_source&quot; : {\n          &quot;id&quot; : &quot;2&quot;,\n          &quot;name&quot; : &quot;Britney&quot;\n        }\n      }\n    ]\n  }\n}\n\n</pre>\n\n\n<h2 id=\"データを読み込んでみる\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%93%E3%81%A7%E3%81%BF%E3%82%8B\"></a>データを読み込んでみる</h2>\n\n\n\n<p>反対に、Elasticsearchに入っているデータからDataFrameを作ってみたいと思います。以下は、先程書き込んだインデクスのデータを読み込んでいます:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\nscala&gt; val dfFromEs = spark.read.format(&quot;es&quot;).load(&quot;test-index/_doc&quot;)\ndfFromEs: org.apache.spark.sql.DataFrame = [id: string, name: string]\n\nscala&gt; dfFromEs.printSchema\nroot\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n</pre>\n\n\n<p><code>spark.read.format(\"es\")</code>&nbsp;でリーダーを初期化して、&nbsp;<code>.load(インデクス名)</code>&nbsp;で読み込むだけです。<br>replからの応答で分かりますが、入力した通りのドキュメント構造が再現されているので、実際にRDD化してcollectしてみましょう:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\nscala&gt; dfFromEs.rdd.map { case org.apache.spark.sql.Row(id: String, name: String) =&gt; Map(&quot;id&quot; -&gt; id, &quot;name&quot; -&gt; name) } .collect\nresN: Array[scala.collection.immutable.Map[String,String]] = Array(Map(id -&gt; 2, name -&gt; Britney), Map(id -&gt; 1, name -&gt; Alice))\n</pre>\n\n\n<p>無事取得する事ができました。</p>\n\n\n\n<h2 id=\"設定について\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#%E8%A8%AD%E5%AE%9A%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"></a>設定について</h2>\n\n\n\n<p>さて、<code>spark-shell</code>&nbsp;実行時にいくつか設定を指定したと思いますが、設定は各オペレーションを実行時にもオーバーライド指定する事が可能です。</p>\n\n\n\n<p><strong>書き込み時</strong></p>\n\n\n\n<p>例えば、先程の書き込み例のJSONにおいて、&nbsp;<code>id</code>&nbsp;をElasticsearchのメタフィールドである&nbsp;<code>_id</code>&nbsp;にマッピングし、データを更新可能にしたいとします。<br>また、その際ドキュメント自体からは&nbsp;<code>id</code>&nbsp;を削除してみましょう:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\nscala&gt; val inputData = Seq( Map(&quot;id&quot; -&gt; &quot;1&quot;, &quot;name&quot; -&gt; &quot;Alice&quot;), Map(&quot;id&quot; -&gt; &quot;2&quot;, &quot;name&quot; -&gt; &quot;Britney&quot;) )\ninputData: Seq[scala.collection.immutable.Map[String,String]] = List(Map(id -&gt; 1, name -&gt; Alice), Map(id -&gt; 2, name -&gt; Britney))\n\nscala&gt; sc.makeRDD(inputData).saveToEs(&quot;test-index-v2/_doc&quot;, Map( &quot;es.mapping.id&quot; -&gt; &quot;id&quot;, &quot;es.mapping.exclude&quot; -&gt; &quot;id&quot; ))\n</pre>\n\n\n<p><code>saveToEs</code>&nbsp;の第2引数（<code>org.elasticsearch.spark.rdd.EsSpark.saveToEs</code>&nbsp;の場合は第3引数）にMapで設定を追加指定する事が可能で、この設定は&nbsp;<code>spark-shell</code>&nbsp;実行時に指定した設定とマージされます。<br>ちなみに<code>es.mapping.id</code> ではエントリのどのフィールドを <code>_id</code> にマップするか、また <code>es.mapping.exclude</code> ではどのフィールドを書き込み対象から外すかをそれぞれ指定できます。</p>\n\n\n\n<p>実際にデータを見てみましょう:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\n$ curl vpc-my-es-xxxxxxxxxxxxxxxxxxxxxxx.us-west-2.es.amazonaws.com/test-index-v2/_search?pretty\n{\n  ...,\n  &quot;hits&quot; : {\n    ...,\n    &quot;hits&quot; : [\n      {\n        &quot;_index&quot; : &quot;test-index-v2&quot;,\n        &quot;_type&quot; : &quot;_doc&quot;,\n        &quot;_id&quot; : &quot;2&quot;,\n        &quot;_score&quot; : 1.0,\n        &quot;_source&quot; : {\n          &quot;name&quot; : &quot;Britney&quot;\n        }\n      },\n      {\n        &quot;_index&quot; : &quot;test-index-v2&quot;,\n        &quot;_type&quot; : &quot;_doc&quot;,\n        &quot;_id&quot; : &quot;1&quot;,\n        &quot;_score&quot; : 1.0,\n        &quot;_source&quot; : {\n          &quot;name&quot; : &quot;Alice&quot;\n        }\n      }\n    ]\n  }\n}\n</pre>\n\n\n<p>想定した通りデータが入っています。また、実行結果は割愛しますが、先程述べた通り&nbsp;<code>_id</code>&nbsp;を指定しているので、既存データの更新を行う事ができます。</p>\n\n\n\n<p><strong>読み込み時</strong></p>\n\n\n\n<p>読み込み時にも同様の事が可能です。例えば、先程&nbsp;<code>_id</code>&nbsp;を指定して書き込んだ方はドキュメント自体は&nbsp;<code>id</code>&nbsp;を含めないようにしましたが、このままだとDataFrame側でidが参照できず不便な事があります。<br>そこで、以下のように <code>es.read.metadata</code> オプションに<code>true</code>を指定して読み込んでみましょう:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\nscala&gt; val dfFromEs = spark.read.format(&quot;es&quot;).options(Map( &quot;es.read.metadata&quot; -&gt; &quot;true&quot; )).load(&quot;test-index-v2/_doc&quot;)\ndfFromEs: org.apache.spark.sql.DataFrame = [name: string, _metadata: map&lt;string,string&gt;]\n\nscala&gt; dfFromEs.printSchema\nroot\n |-- name: string (nullable = true)\n |-- _metadata: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n</pre>\n\n\n<p>先程とは異なり、&nbsp;<code>_metadata</code>&nbsp;と言うオブジェクトが入れ子になっています。<br>ここに&nbsp;<code>_id</code>&nbsp;やら&nbsp;<code>_type</code>&nbsp;が入っているので、例えば入力時のMapを再現したい場合、RDD化してから取り出してもいいですし、次のようにしてDataFrame上でカラム化しておく事もできます:</p>\n\n\n<pre class=\"brush: plain; title: ; notranslate\" title=\"\">\nscala&gt; dfFromEs.select(col(&quot;_metadata&quot;)(&quot;_id&quot;).alias(&quot;id&quot;), col(&quot;name&quot;)).rdd.map { case org.apache.spark.sql.Row(id: String, name: String) =&gt; Map(&quot;id&quot; -&gt; id, &quot;name&quot; -&gt; name) } .collect\nresN: Array[scala.collection.immutable.Map[String,String]] = Array(Map(id -&gt; 2, name -&gt; Britney!!), Map(id -&gt; 1, name -&gt; Alice))\n</pre>\n\n\n<h2 id=\"おすすめの設定\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#%E3%81%8A%E3%81%99%E3%81%99%E3%82%81%E3%81%AE%E8%A8%AD%E5%AE%9A\"></a>おすすめの設定</h2>\n\n\n\n<p>設定について既にいくつか述べましたが、今回のユースケースでは更に以下の設定を追加で指定しています:</p>\n\n\n\n<ul><li class=\"\"><code>es.batch.size.bytes</code>: (default: 1mb)</li><li class=\"\"><code>es.batch.size.entries</code>: (default 1000)</li><li class=\"\"><code>es.scroll.size</code>: (default: 50)</li></ul>\n\n\n\n<p>いずれもパフォーマンスに関係がある設定となっており、最初の&nbsp;<code>es.batch.size.bytes</code>&nbsp;と&nbsp;<code>es.batch.size.entries</code>&nbsp;は書き込み時にBulk APIを呼び出す際のサイズで、コンポーズしたJSONエントリがいずれかのサイズに到達したらAPIがコールされると言う内容になっており、当然ながら大きいサイズを指定する事でElasticsearchへの接続数が減ります。<br>設定値についてはドキュメントサイズの傾向や、クラスタの設定、ネットワークの構成、Spark上でのタスク数に依存する為正解はありませんが、エラーが頻発しない範囲で、可能な限り大きい数値を使って調整しています。</p>\n\n\n\n<p><code>es.scroll.size</code>&nbsp;も同様で、Elasticsearchに投入するようなデータ量だと50では少なすぎで、例えば今回の量だと60万回もElasticsearchのScroll APIを呼び出さないといけなくなり、現実的ではないのでこれも可能な限り大きい値を設定しておく必要があります。</p>\n\n\n\n<p>※パフォーマンスについては<a href=\"https://www.elastic.co/guide/en/elasticsearch/hadoop/6.7/performance.html#_write_performance\">公式ドキュメントのこのページ</a>が詳しいです。</p>\n\n\n\n<h2 id=\"まとめ\"><a href=\"https://hackmd.io/Cw5kP4jZRVuLN_kpOESqSw?view#%E3%81%BE%E3%81%A8%E3%82%81\"></a>まとめ</h2>\n\n\n\n<p>Elasticsearchが提供するインテグレーションを使うと、Sparkとの連携が楽に出ると言う事が分かりました。<br>現在はまだ本格的な運用フェーズに入っていない為細かいチューニング等はまだしていないので、また別の機会でそのあたりをいつかご紹介できればと思います。</p>\n","dateObject":"2019-06-17T10:59:12.000Z","date":"June 17, 2019","categories":[{"name":"Uncategorized","slug":"uncategorized"}],"tags":[{"name":"Elasticsearch","slug":"elasticsearch"},{"name":"Hadoop","slug":"hadoop"},{"name":"Scala","slug":"scala"},{"name":"Spark","slug":"spark"}],"author":{"name":"issei_m","slug":"issei"},"featured_media":{"media_details":{"sizes":{"large":null,"medium_large":{"source_url":"https://i2.wp.com/stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/es_spark.png?fit=768%2C308&ssl=1","height":308,"width":768}}},"source_url":"https://stg-engineering-wp.mobalab.net/wp-content/uploads/2019/06/es_spark.png"},"wordpress_id":947}},"pageContext":{"id":"8cc962b4-6e34-529e-a13a-ebc98f841ffb","nextPath":"/2019/06/10/aws-lambda上でwebスクレイピング/","nextTitle":"AWS Lambda上でWebスクレイピング","prevPath":"/2019/06/21/laravelの多対多のリレーションについて/","prevTitle":"Laravelの多対多のリレーションについて"}}}